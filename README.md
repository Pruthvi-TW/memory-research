# Integrated Lending Context Chatbot

A comprehensive chatbot system that combines vector search and graph database technologies to provide context-aware responses about lending processes.

## ğŸ—ï¸ Architecture Overview

### Enhanced Processing Flow with mem0
```
[User] â†’ [Chatbot Interface] â†’ [mem0 Memory] â†’ [Vector Store] â†’ [Graph DB (Neo4j)] â†’ [LLM (Claude)] â†’ [Response/Code]
                                     â†“
                              [Conversation Memory]
```

### System Components

1. **Frontend**: React-based chat interface
2. **mem0 Memory Layer**: Semantic memory for context and conversation storage
3. **Vector Store**: Chroma DB for semantic document search
4. **Graph Database**: Neo4j for relationship-based context retrieval
5. **LLM Integration**: Anthropic Claude for response generation

### Enhanced Context Retrieval Strategy with mem0

1. **mem0 Semantic Memory**: Retrieve relevant context from persistent semantic memory
2. **Vector Search**: Use Chroma DB to find semantically similar documents
3. **Graph Enhancement**: Enrich results using Neo4j relationship traversal
4. **Conversation Context**: Include relevant conversation history from mem0
5. **Enhanced Fusion**: Advanced scoring combining all context sources
6. **LLM Generation**: Generate responses using the multi-layered enriched context

## ğŸ“ Project Structure

```
integrated-lending-chatbot/
â”œâ”€â”€ frontend/                   # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ services/          # API services
â”‚   â”‚   â””â”€â”€ App.tsx           # Main application
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ mem0/                      # mem0 semantic memory layer
â”‚   â”œâ”€â”€ mem0_manager.py       # mem0 memory operations
â”‚   â”œâ”€â”€ mem0_context_extractor.py # Lending context extraction
â”‚   â”œâ”€â”€ mem0_integration_service.py # Multi-layer integration
â”‚   â”œâ”€â”€ mem0_config.py        # Configuration management
â”‚   â””â”€â”€ README.md             # mem0 layer documentation
â”œâ”€â”€ vector/                    # Vector store implementation
â”‚   â”œâ”€â”€ vector_service.py     # Chroma DB operations
â”‚   â”œâ”€â”€ document_processor.py # Document processing
â”‚   â””â”€â”€ embeddings.py        # Embedding utilities
â”œâ”€â”€ graph/                    # Graph database implementation
â”‚   â”œâ”€â”€ neo4j_service.py     # Neo4j operations
â”‚   â”œâ”€â”€ context_repository.py # Graph data access
â”‚   â””â”€â”€ schema.py            # Graph schema
â”œâ”€â”€ services/                 # Business logic layer
â”‚   â”œâ”€â”€ integration_service.py # Vector + Graph integration
â”‚   â”œâ”€â”€ chat_service.py       # LLM integration
â”‚   â””â”€â”€ context_service.py    # Context orchestration
â”œâ”€â”€ models/                   # Data models
â”‚   â””â”€â”€ chat_models.py       # Pydantic models
â”œâ”€â”€ Lending/                  # Lending context directory
â”‚   â”œâ”€â”€ Capabilities/         # Capability-specific content
â”‚   â””â”€â”€ CommonPrompts/        # Shared guidelines
â”œâ”€â”€ main.py                   # FastAPI application
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ .env.example             # Environment variables template
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 18+ and npm
- Neo4j Database (Community Edition or Desktop)
- Qdrant Vector Database (for mem0)
- Anthropic API Key

### Installation

1. **Setup environment**:
   ```bash
   cd integrated-lending-chatbot
   cp .env.example .env
   # Edit .env with your credentials:
   # - NEO4J_PASSWORD=your_neo4j_password
   # - ANTHROPIC_API_KEY=your_anthropic_key
   ```

2. **Install Python dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Install and build frontend**:
   ```bash
   cd frontend
   npm install
   npm run build
   cd ..
   ```

4. **Start databases**:
   ```bash
   # Start Neo4j database
   # If using Neo4j Desktop, start your database
   # If using Community Edition:
   neo4j start
   
   # Start Qdrant for mem0 (using Docker)
   docker run -p 6333:6333 qdrant/qdrant
   ```

5. **Start the application**:
   ```bash
   python main.py
   # Application will be available at http://localhost:8000
   ```

6. **Initialize context** (via web interface or API):
   - **Web Interface**: Click "Initialize Context" button in the chat interface
   - **API**: 
     ```bash
     curl -X POST "http://localhost:8000/api/initialize-context" \
          -H "Content-Type: application/json" \
          -d '{"lending_path": "../Lending"}'
     ```

### Development Mode

For development with hot reload:

```bash
# Terminal 1: Start backend with reload
uvicorn main:app --reload --port 8000

# Terminal 2: Start React dev server
cd frontend
npm run dev
# Frontend will be available at http://localhost:3000
```

## ğŸ”„ Integration Benefits

### Vector + Graph Synergy

1. **Semantic Discovery**: Vector search finds conceptually similar content
2. **Relationship Enhancement**: Graph traversal discovers related concepts and flows
3. **Context Ranking**: Combined scoring provides better relevance ranking
4. **Comprehensive Coverage**: Ensures both semantic and structural relationships are captured

### Enhanced Query Processing

- **Multi-modal Search**: Combines text similarity with relationship strength
- **Context Expansion**: Graph relationships expand the context beyond direct matches
- **Relevance Scoring**: Weighted combination of vector similarity and graph centrality
- **Dynamic Context**: Adapts context based on conversation history stored in graph

## ğŸ“Š Performance Optimizations

- **Hybrid Indexing**: Vector embeddings + Neo4j indexes
- **Caching Strategy**: Redis for frequently accessed contexts
- **Batch Processing**: Efficient document processing and embedding generation
- **Connection Pooling**: Optimized database connections

## ğŸ”§ API Endpoints

### Chat Endpoint
```bash
POST /api/chat
{
  "message": "How does eKYC verification work?",
  "session_id": "optional-session-id"
}
```

### Initialize Context
```bash
POST /api/initialize-context
{
  "lending_path": "../Lending"
}
```

### Health Check
```bash
GET /api/health
```

## ğŸ› ï¸ Development

### Running in Development Mode

```bash
# Terminal 1: Start backend with hot reload
uvicorn main:app --reload --port 8000

# Terminal 2: Start React dev server
cd frontend
npm run dev
```

### Testing the Integration

```bash
# Test vector search
curl -X POST "http://localhost:8000/api/test/vector-search" \
     -H "Content-Type: application/json" \
     -d '{"query": "eKYC verification process"}'

# Test graph search
curl -X POST "http://localhost:8000/api/test/graph-search" \
     -H "Content-Type: application/json" \
     -d '{"query": "PAN validation"}'

# Test integrated search
curl -X POST "http://localhost:8000/api/test/integrated-search" \
     -H "Content-Type: application/json" \
     -d '{"query": "document verification workflow"}'
```

## ğŸ“ˆ Monitoring & Analytics

- **Query Performance**: Track vector search and graph query times
- **Context Quality**: Monitor relevance scores and user feedback
- **System Health**: Database connections, embedding model status
- **Usage Patterns**: Popular queries and context utilization

## ğŸ”’ Security & Compliance

- **Data Privacy**: PII masking in logs and responses
- **API Security**: Rate limiting and authentication
- **Database Security**: Encrypted connections and access controls
- **Audit Trail**: Complete conversation and context usage logging